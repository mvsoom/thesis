\chapter{Introduction to Bayesian methods\label{chapter:3}}

\section{Basics of Bayesian methods\label{bayesian-basics}}

Models scientific inference.
It has been shown again and again that the unique way to do this is the probabilistic or Bayesian approach \citep{Jaynes2003,Knuth2012}.
compression prior to posterior.

The disadvantage is computational complexity because inference in the Bayesian framework is essentially contingency bookkeeping: we never throw a possibility away, we just keep reweighing.
There are many opportunities for approximation, because we typically only want to predict low-dimensional quantities \citep{MacKay1996}; we generally care only about roughly getting the probability mass in the right place.

The main advantages that I see of a Bayesian approach to acoustic phonetics and scientific problems in general are:
\begin{itemize}
	\item Clear foundations that connect to our common sense.
	These foundations might help for scientific agreement around controversies, since the algebra is unique and follows from compelling axioms.\footnote{%
		A striking example is the current impasse about scale-free networks (``rare and everywhere'') in network science \citep{Holme2019}; while researchers might disagree about the models, at least they can agree on the algebra.
	}
	
	\item Thanks to this connection, possible to see old things in a new light.
	For example, Fourier transform (Chapter~\ref{detrending-waveforms}). % TODO: Change to the containing Section rather than Chapter
	Other example: $\ell^1$ optimization (``the future belongs to $\ell^1$ optimization'' \citep{Strang2019}). $\ell^1$ is Laplace distribution on the errors, i.e., only know general magnitude instead of second moment.
	More speculations: stochastic gradient descent as variational inference? % See blog post
	
	\item Inference is completely mechanical once the model $p(x,\theta)$ is specified.
	Simplicity: sum and product rules suffice.
	
	\item In addition, \cite{MacKay2005} emphasizes the value of the fact that Bayesian methods force one to make one's assumptions implicit.
	Standardized way to input assumptions, which is leveraged by PPLs.
	compatible with off-the-shelf exploration algorithms
	
	\item (See my reading group presentation on Skilling paper for more).
\end{itemize}

\paragraph{Generative models} specify the full joint distribution $p(\bd,\btheta)$ over data $\bd$ and parameters $\btheta$.
If data is seen as the output of a system, inferring the parameters can be seens as speech inversion.
A fully generative model is thus a quite natural way to tackle inverse problems.
Inverse problems naturally admit infinite solutions.
We will see that an essential ingredient for success in this task is regularization, i.e., impose properties on possible solutions that we already know, from prior experience, that they must have.
The approach we take in this thesis is to exlicitly use knowledge from acoustic phonetics, a well developed field of science for the last 60 years.

\section{Introduction}

If you come up with a bunch of methods to solve a given problem (such as fit parameters to empirical data) and you're unsure whether it is `consistent'?
If your methods are phraseable within Bayesian probabilistic theory, then you are automatically guaranteed that they are \emph{mathematically} sound, i.e., no contradiction can be derived from it (of course when you make approximations and your assumptions are not met, then contradictions can arise).
But more often we are interested in whether the methods are \emph{conceptually} sound, i.e., do they make sense in a general sense, are they in agreement with whatever we know to be (approximately) true about the problem?
To know this, we must examine what we have input to the theory, i.e., our prior information and assumptions.
These are `encoded' by our priors and choices of likelihood functions (and, in practice, approximation schemes).
This is much harder to assess because there is no unique prescription to translate prior information (which is often vague and verbal) into a mathematical prescription.
There are, however, certain ways to translate prior information.
We will make use of two principles extensively in this thesis: ignorance priors (transformation groups) and the principle of maximum entropy.
(Next sections.)
Then we look at the computational implementations of inference through the probabilistic language paradigm (nested sampling, perhaps HMC).

\section{Fundamentals}

Introduce prior, likelihood, evidence and posterior, as input and output as in \citep{Skilling2004}.
``Probability calculus is a calculus for manipulating numbers (ratios, actually). ... It is a language in which we can express our opinions.'' \citep[p.~3]{Skilling2008}
It is strange to criticize a language, but one can criticize what's being said (the model) and how it's said (the approximations) [from my reading group presentation on Skilling].
"Probability calculus is which shows us how to modify our preferences in the light of experience. But it does not tell us what our initial preferences should be. The language does not tell us what to say." Skilling in Buck1991
How the Bayesian algebra is motivated:
\begin{itemize}
\item Cox (and Jaynes): connect to common sense
\item Bernardo: connect to decision theory
\item Knuth and Skilling: connect to fundamentals
\end{itemize}

See `Bayesian probability' document by Herman Bruyninckx (KULeuven) for additional structure.

I give a brief introduction to the Bayesian methods actually used in this thesis.
Bayesian methods are not a pack of unrelated techniques, rather the appeal of Bayesian methods is that the form a coherent framework towards solving problems under uncertainty.
It can be seen like a ``ISO''-standardized language to pose and solve problems.
For example, it is probably uncontroversial to say that Bayes can unite many machine learning methods \citep{Murphy2022}), while in other fields such as physics, similar unifying Bayesian formalisms have been proposed recently \citep{Skilling2021} but are more controversial.

For a general introduction to ``Bayesian thinking'' I recommend \cite{Jaynes2003}.
A practical and lightweight introduction is in \cite{Sivia2006}.
And a more fully-fledged modern introduction geared towards physics is in \cite{vonderLinden2014}.

The central tenet of Bayesian probability theory is that \emph{probabilities do not describe reality, only our information about reality} \citep{Jaynes1993}.

It is often said that the difference between frequentist statistics and Bayesian statistics is that the former only uses sampling information while the latter also uses prior information \citep[e.g.,][]{Strang2019}, but this is inaccurate.
For example, you cannot integrate over parameters because they are not seen as `true' random variables.
For many simple and canonical examples where there is no prior information, Bayesian and frequentist methods do agree.
MacKay (2003) emphasizes that a virtue of Bayes is that it is necessary to make explicit your assumptions, in contrast to frequentistic statistics.
In fact, the assumptions can be made explicit through a ``standardized method'', i.e., assigning probability distributions (more presicely: specifying the inputs: prior and likelihood).
It is precisely because of this ``standardized way'' of specifying assumptions that probabilistic programming languages (PPLs) are possible and are in fact on the rise (e.g. Stan), especially when combined with domain specific languages (DSL) like possible in Julia.
In this thesis we will make use of these PPLs.
In light of this, we feel that a slightly stronger statement than MacKay's is more appropriate: it is an inherent deficit of frequentist statistics that there is no standardized framework to express one's assumptions; indeed, this is fundamental, because ``without assumptions you cannot do inference'' (MacKay).

The disadvantage is computational complexity because inference in the Bayesian framework is essentially contingency bookkeeping: we never throw a possibility away, we just keep reweighing.
There are many opportunities for approximation, because we typically only want to predict low-dimensional quantities \citep{MacKay1996}; we generally care only about roughly getting the probability mass in the right place.
(For example, the chapter in which we derive distributions of formants).
So the complexity can often be managed, but whenever computing budget allows, sampling methods such as nested sampling are advised.

We see that not mentioning a possibility is equivalent to assigning it a zero probability.
Indeed, an a priori zero probability can never be recovered a posteriori.
This is why the KL divergence is asymmetric.

\begin{quote}
The curve described by a simple molecule of air or vapor is regulated in a manner just as certain as the planetary orbits; the only difference between them is that which comes from our ignorace.
Probability is relative, in part to this ignorance, in part to our knowledge.
\end{quote}
Laplace, Philosophical Essay on Probabilities (1814), page 5.
% From https://www.youtube.com/watch?v=ZwqE5F26FF0&list=PLZ_xn3EIbxZGcqHGFj-P_SI6OCXy8TfoL&t=846s&ab_channel=GaussianProcessSummerSchool

Priors:
\begin{quote}
It should have become apparent that setting a prior can be a creative, almost artistic,
task. The aim is not to “get it right” (for then why would one ever need data?), but to
assign a useful model for learning about the subject. \cite{Skilling2005}
\end{quote}

\section{Invariant priors: group transformation principle}

Logically this comes before ME distribution.

\section{Maximum Entropy Distributions}

Kullback-Leibler: inference is inherently asymmetric due to independence requirement (on which science is based.)
Can't unlearn an impossibiliry

(Strictly speaking not a Bayesian method (Jaynes 2003, see preface), but more of general probabilistic inference \citep{Knuth2012}.)

In this work we only use ME distributions.
These are distributions that are maximally noncommital wrt. given information (constraints).
The two important applications of this principle are the Pareto chain distribution (Chap. 4) and the Gaussian distribution.

The univariate Gaussian distribution is the most used distribution since it is the minimal (in a ME sense) objects to represent uncertainty about a quantity.

\section{Bayesian Linear Regression}

\citep{Fitzgerald1999}

$f(t) = \sum_k \alpha_k \phi_k(t)$

The regularizing magic happens when we integrate out the amplitudes and noise power to obtain a Student-t distribution.

The choice of prior for the amplitudes and the form of basis functions are crucial.
Typically interpreted as regularization such as ridge regression or sparse Laplace stuff.
But, we will see that a very powerful way to obtain these choices is by approximating a Gaussian process by projecting it down to a finite dimensional Gaussian (reduced-rank GPs).

\section{Gaussian Processes}

% Very good reference = "A practical guide to GPs" <https://infallible-thompson-49de36.netlify.app/>

Use MacKay's derivation for the RBF kernel starting from Bayesian linear regression (function space view) to motivate Gaussian processes.

Introduce update equations: phrasing as a $O(N^2)$ projection $(I - P)^{1/2}$.

\subsection{Stationary kernels}

Important because by the invariance principle, ignorance of specific locations implies kernel invariant under translation: stationary kernels.

Stationary are thus suited ``to start out with'', and then to add increasing information, as we do with the glottal flow.

\paragraph{Bochner's theorem.} Also important, they have an interpretation in the frequency domain, which is important for our applications.

\paragraph{Mercer theorem.} This shows that stationary kernels have eigenfunctions $e^{ikx}$.

\subsection{Reduced-rank GPs}

This is just Bayesian linear regression! The connection between Mercer theorem and KL expansion: they are identical.

All of the highly praised ``automatic regularizing/robustness against overfitting'' capacities of GPs can in fact be reproduced by humble Bayesian linear regressing.
But note: what the latter \emph{cannot} reproduce is the ``Bayesian nonparametrics'' feature of being adaptive to an infinite amount of data: there is no information bottleneck.
However, we can argue that this is not really the case in our machine learning: we are not dealing with a huge amount of data that we need to learn features from; we are in a small amount of data regime that, armed with ``sophisticatedly simple'' models \citep{Jaynes1985}, we want to make the most of.
In other words, we aim for accuracy and explicit understanding.


\subsection{Nested sampling}

See my reading group presentation on Skilling paper for how to present. (Compression factor, log Z, etc.)

\section{Discussion}

\citedepigraph{%
The uncertainty of my judgment is so equally balanced in most occurrences, that I could willingly refer it to be decided by the chance of a die.
}{Michel de Montaigne (1580)}{deMontaigne1910}