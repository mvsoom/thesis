% !TeX root = ../thesis.tex
\chapter{Nonparametric glottal inverse filtering\label{chapter:6}}

\begin{chaptersections}{%
We apply BNGIF.
}

Joint inverse filtering is relatively new: Alzamendi and Schlotthauer (2017)

This is standard semiparametric GP regression.
Another GP reference is \citep{MacKay1998}
Latent GP function is "closely observable" because Gaussian errorbars are very small
But in these problems the likelihood function often has small impact \citep{Murray2010a} and the continuity constraints are much more important
This is regularization in action: our constraints are very important because the problem is so underdetermined


Since source $u'(t)$ and filter $h(t)$ are assumed to be independent, we can sample an $s(t)$ waveform from \eqref{eq:suh} using the following sampling procedure: first sample an $u(t) \sim \piGP(u(t))$, then differentiate it to obtain $u'(t)$, then convolve $u'(t)$ with an independently sampled $h(t)$, either as $h(t) \sim \piPZ(h(t))$ or as $h(t) \sim \piAP(h(t))$.

How do the methods in these two broad classes compare?
We are not aware of any study that compares the performance of these two approaches systematically, but it is possible to make a few general statements.
Inverse filtering methods are generally efficient and nonparametric, while joint source-filter optimization methods have the distinct advantage of cleanly separating $u(t)$ and $\htilde(x)$ from the outset.
In doing so they avoid having to derive $u(t)$ directly from a filter estimate $\hat\htilde(x)$ that inevitably contains pronounced effects from the former, to which \cite[][p.~94]{Schroeder1999} refers as a ``suspiciously circular sounding `bootstrap' method.''\footnote{%
	A slightly polemic take on this is expressed in the second edition of \emph{Numerical Recipes} [LPC means linear predictive coding, which is synonymous with LP in this context]:
	\begin{quote}
		Some people believe that it is interesting to analyze a signal by LPC, even when the residuals are not small.
		The [residuals] are then interpreted as the
		underlying “input signal” which, when filtered through the all-poles filter defined by the LP coefficients, produces the observed ``output signal.'' LPC reveals simultaneously, it is said, the nature of the filter and the particular input that is driving it. We are skeptical of these applications;
		the literature, however, is full of extravagant claims.
		\citep[][p.~572]{Press1992}
	\end{quote}
	It is important to point out that this quote is about the use of LP for modeling \emph{general} time series; in the case of inverse filtering however the time series involved are speech signals $s(t)$, and the use of all-pole filters implicit in LP is in fact motivated by an approximation of the wave equation underlying the physics of speech production \citep{Flanagan1965}.
}


BNGIF avoids harmonic attraction completely as it is does not employ LP analysis; there is no inherent smoothing of the spectral envelope going on.
This helps with performance in high $F_0$ environments.
But BNGIF's multi-period analysis also helps: it is pitch-synchronous, but also allows multiple pitch periods, allowing ``bleed'' from adjacent periods.
This also reduces the sensitivity to the fact that the closed phase of the glottal cycle is reduced in high $F_0$ conditions, as BNGIF can handle the transients from adjacent periods in a wholesome way.
This issue of reduced duration of the closed phase mainly affects CP methods (that also suffer from harmonic attraction):
``Apart from the need
for accurate GCI information, the problem with the CP anal-
ysis method is that the temporal duration of the closed phase
decreases as the pitch of the voice increases. The limited number
of samples on which the spectral envelope analysis is performed
increases errors in vocal tract models especially when combined
with the need for accurate GCI information.'' \citep{Airaksinen2014}

More quotes about F0 bias (which is the same as harmonic attraction):
Recent pitch-synchronous approaches for LPC (e.g.,
Alku et al., 2013; Gowda et al., 2020) were specifically
designed to overcome F0 bias but require very accurate glot-
tal pulse information, usually provided by an EGG signal
(Alku et al., 2013). However, requiring EGG to be recorded
along with the audio signal severely restricts the usefulness
of pitch-synchronous LPC. \citep{Whalen2022}

Most formant tracking algorithms attempt to correct
formant selection error (i.e., formant jumps; e.g., wrongly
selecting F3 as F2) and usually result in smoother sets of
formant values but cannot correct for bias toward the nearest
strong harmonic; one can end up with very smooth formant
tracks at very wrong frequencies. The default tracking func-
tion in Praat implements the Viterbi algorithm (Viterbi,
1967) to select the optimal (smoother) paths through for-
mant candidates, but it does not change the LPC-estimated
formant value itself (i.e., F0 bias remains). \citep{Whalen2022}




\section{Introduction}

Finally, the data is just the sum of the ideal model $s(t)$ and the error $\be$.
Note that both of these are expressed as Gaussians.
Thus the observed data is just a Gaussian process.
So can write an indexable expression too and treat the data $d(t)$ as a \emph{function} for which we only have observations $\bd = d_{1:N} = \{d(t_n)\}_N$ at times $\bt$.
\begin{equation}
    d(t) \sim \GaussianProcess(0,k_\btheta)
\end{equation}
So $d(t) = u'(t) * h(t) + e(t)$ and since $u'(t) \sim \GaussianProcess(0,\btheta_s)$, $h(t)$ depends on $\btheta_f$ and $e(t) \sim \GaussianProcess(0,\sigma_n^2 \delta(t-t'))$, by linearity of convolution and additive errors, $d(t)$ is still a GP with kernel determined by $\btheta$.

Typically we only use 3 pole pairs as is often done, for example in \citep{Wang2016a}.
Note however these are PZ poles and not AP poles as almost always done.


- Discuss pre-emphasis as mutilation of the data in the same style as "The
  folly of pre-filtering data" [Jaynes2003, p. 521]. [Fulop2011, p. 91] also
  recognizes that there is no need anymore for this as modern dynamic range is
  large enough ($\ge$ 50 dB, i.e. a factor 10,000 or 14 quantization bits depth).
  
  I do not know if pre-emphasis is still used nowadays. (it is) But in any case the
  **sliding tapering window** is also a data mutilation which we can treat in
  the same way.
  
- Nasals apparently often have formants close together. These can be better
  resolved with the Bayesian spectrum approach compared to traditional
  approaches.


ADVI is an example of MacKays "hunting for a good basis".
Finding the mode $x$ in a probability $p(x|\theta)$ is basis dependent (nonlinear transformation can put the mode anywhere).
Optimizing $\theta$ in an evidence/likelihood such as $p(x|\theta)$ is actually basis independent.

If there are correlations in p(theta|alpha), we can only partly observe T and the poles and let correlations constrain the OQ etc. Even better: if no Praat estimates are available, we do not condition on them and our prior will still work, just less constrained

- up to F4 suffices: ``Practically, in speech analysis, it is neces-
sary to consider only about the first four formant frequencies.'' \citep{Peterson1966}
- antiformants are usually ignored.
``Practically, it is necessary to consider only about the first two conso-
nant antiresonances in speech analysis'' \citep{Peterson1966}

In this paper we will always work with signals resampled to a bandwidth 5 kHz ($f_s = \text{10 kHz}$, which essentially limits us to the first three {or} four formants \citep[p.~20]{Rabiner1993}.

Note that $\htilde(x)$ is in fact parametrized for both inverse filtering and joint source-filter optimization approach classes, but LP can solve for these parameters very efficiently -- efficiently convex optimization -- while we can't do that.
We can however use incremental optimization in the PZ model which is similar to what IAIF does and \citep{Bretthorst1989} do: explain step by step pieces with large energy of the signal and subtract them and readjust current estimates.
``The IAIF-method is based on a priori knowledge
about the overall shape of the transfer function of
the vocal tract (Figure 2(b)). In the case of vowels
this is of an all-pass nature having some high
energy regions, the formants.'' \citep{Alku1992}

\section{Sequential inference}

\shloppy{NOTE: this is similar to local updating (Gibbs sampling like), see \citep{Murray2010} Section 3.3.}

Inference with reduced-rank GPs is simply linear regression.
BNGIF is linear with respect to new pitch periods (the $N_P$ dimension) and new pole pairs (the $K$ dimension) and new pole pairs in the PZ case.
This opens up the possiblity of using sequential inference, where the current model is refined step by step by incrementing $N_P$ or $K$.
This is similar in philosophy to several other GIF approaches that use different steps to refine the GF estimate \citep[such as][]{Alku1992} or ease the optimization in joint source-filter optimization approaches \citep[for example,][]{Fu2006,Bleyer2017}.

The idea is simple:
for a given $\mathcal{M}(N_P,K)$ model posterior samples $\bthetavs_{N_P,K} \sim p(\bthetavs_{N_P,K}|D,\mathcal{M}(N_P,K))$ are obtained, which are then used to constrain the prior $p(\bthetavs_{N_P+n,K+k}|\mathcal{M}(N_P+n,K+k))$ for the `next' model $\mathcal{M}(N_P+n,K+k))$ where $n,k \geq 1$.
In other use we take advantage of the nested model structure by performing inference one step at a time and propagating information downstream to the next model.\footnote{%
Whereas a similar strategy is employed for orthogonal expansions in nested model \citep[][p.~472]{vonderLinden2014} (also done in pioneering work in Bayesian spectrum analysis \citep[][p.~73]{Bretthorst1988}), the situation is different here (and more complicated) because our priors $p(\bthetavs)$ are highly correlated, so we can anticipate a bit more involved mathematical analysis.
}

The updating procedure is very general and works as follows.
Assume that the parameters $\btheta$ of a model can be split into two parts and have a MVN prior:
\begin{equation}
	\btheta = \mqty(\bx \\ \by), \quad p(\btheta) = \mathcal{N}\left(\mqty(\bmu_x \\ \bmu_y),\mqty(\Sigma_{xx} & \Sigma_{xy}\\ \Sigma_{yx} & \Sigma_{yy}) \right)
\end{equation}
where $\Sigma_{yx} = \Sigma_{xy}^T$.
New information about the $\bx$ component arrives in the form of posterior samples $\hat X = \{\hat\bx_i\}_{i=1}^I$ which are inferred from a model that is below the current one in the nested hierarchy, no matter how much down.
This is salient new information that can be used to constrain the prior $p(\btheta)$ further using Bayesian updating:
\begin{equation}
	p(\btheta|\hat X) = p(\bx,\by|\hat X) = p(\by|\bx) p(\bx|\hat X). \label{eq:seqtheta}
\end{equation}
Here $p(\bx|\hat X)$ encodes how much we have learned about the true value of $\bx$ given the estimates by the model down the hierarchy.
For tractability we approximate this by fitting an empirical MVN to the posterior samples $\hat X$:
\begin{equation}
	p(\bx|\hat X) := \mathcal{N}(\hat\bmu_x, \hat\Sigma_{xx}) \label{eq:seqmvn}
\end{equation}
where $\hat\bmu_x = (1/I) \sum_i \hat\bx_i$ is the sample mean and sample covariance $\hat\Sigma_{xx} = (1/I) \sum_i (\hat\bx_i - \hat\bmu) (\hat\bx_i - \hat\bmu)^T$.
(This information is available directly if we use a Laplace approximation or a mean field MVN approximation.)
If the posterior samples $\hat X$ are clustered close together and hence $\bx$ seems already well determined, \eqref{eq:seqmvn} will ensure that for the new model $\bx$ does not need too much exploration, and it will mainly refine $\bx$ further.
Conversely, if the previous model fails to determine $\bx$ accurately, $\hat X$ will be disperse and the new prior for $\bx$ will hardly be constrained.

The first factor $p(\by|\bx)$ in \eqref{eq:seqmvn} is simply the standard MVN conditioning formula and expresses how the new constraints on $\bx$ propagate to $\by$:
\begin{equation}
	p(\by|\bx) = \mathcal{N}(\overline\bmu_y(\bx), \overline\Sigma_{yy})
\end{equation}
where
\begin{align}
	\overline\bmu_y(\bx) &= \bmu_y + \Sigma_{yx} \Sigma_{xx}^{-1} (\bx - \bmu_x)\\
	\overline\Sigma_{yy} &= \Sigma_{yy} - \Sigma_{yx} \Sigma_{xx}^{-1} \Sigma_{xy}
\end{align}
In BNGIF these components are often strongly correlated, so information from the previous model can already constrain possible values for the current model (for example $F_1$ values accurately estimated for given pitch periods will strongly constrain $F_1$ if a new adjacent pitch period is added).

So \eqref{eq:seqtheta} takes the form
\begin{equation}
	p(\btheta|\hat X) = p(\bx,\by|\hat X) = \mathcal{N}(\by|\overline\bmu_y(\bx), \overline\Sigma_{yy}) \mathcal{N}(\bx|\hat\bmu_x, \hat\Sigma_x)
\end{equation}
which can be written as our final result:
\begin{equation}
	p(\btheta|\hat X) = \mathcal{N}\left(\mqty(\hat\bmu_x \\ \overline\bmu_y(\hat\bmu_x)),\mqty(\hat\Sigma_{xx} & \hat\Sigma_{xx} A^T\\ A \hat\Sigma_{xx} & A \hat\Sigma_{xx} A^T + \overline\Sigma_{yy}) \right).
\end{equation}
with $A = \Sigma_{yx} \Sigma_{xx}^{-1}$.
%This uses the formula in https://math.stackexchange.com/questions/3941840/product-of-marginal-gaussian-and-conditional-gaussian

\section{Precision}

In the case of $u(t)$: ``For sustained non-nasalized vowels produced with a modal phonation type in a low (thus more likely male) pitch, many existing GIF methods
are capable of estimating the glottal flow with tolerable accuracy'' \citep{Walker2005,Alku2011}

In the case of $h(t)$ the primary statistics are ofcourse the formant frequencies $\bF$ and bandwidths $\bB$.
Given that ``the uncertainties of formant analysis are widely acknowledged'' \citep[][p.~75]{Kent2018}, the principled uncertainty quantification seems especially called for for the case of the $\bF$ statistic.


The ease of measurements in current systems makes it a 
tempting to think that the issues relating to accuracy of reso-
nance measurement have been solved, and many authors
appear to take that (implicit) stance by reporting without
qualification such values as given by the programs.
Reporting formant values to three (or more) decimal points,
for example, reflects a serious lack of understanding of the
limits of the measurements even if the program’s algorithm
generates such numbers. Although standards at various jour-
nals may differ, it would make sense to round formant val-
ues to the nearest 10 Hz and note that any LPC-measured
formant differences smaller than 50 Hz may be the result of
errors. \citep[][p.~939]{Whalen2022}

Praat uses Burg method which assumes noiseless data, whereas we model noise to introduce uncertainty.
But there is of course much more uncertainty coming from our priors, for example for the amplitudes.

Many people use Praat and Burg:

There are hundreds of reports of speech formants based
on LPC. For example, of nearly 300 papers published in
Journal of Phonetics from 2015 to 2020, all but 2 of the 59
papers that reported formants used the legacy LPC algo-
rithm (Burg, 1967); the majority (79\%) of those were done
with Praat. \citep{Whalen2022}

Handling noise: GIF methods are typically sensitive to noise \citep{Drugman2019}
In our case, if noise level is very high, simply posterior is the prior, graceful degradation, thanks to bayes

Linear Prediction Accuracy Studies \citep[][p.~181]{Fulop2011} only to plusmin 60 Hz

Our approach to source-filter separation is different in that we model the scientific inference process itself rather than designing a pipeline of operations. Our probabilistic inverse filtering method uses Bayesian inference to infer the source and filter from the observed speech signal. This approach allows us to handle uncertainty in a more principled way.
This is uncommon, but has happened before: \citep{Auvinen2014}

More concretely, it seemed
possible to surpass the (often best-case) F0/4 accuracy baseline for formant frequencies
currently achievable with LPC methods (Kent \& Vorperian 2018), with a similar positive
effect on the accuracy of formant bandwidth measurement

\section{Discussion}

\paragraph{Error quantification}
Typically all kinds of statistics such as H1-H2, NAQ etc are used to quantify the quality of the recovered GF of a GIF algorithm.
Note that we can calculate $p(u|d,M)$ as a standard nested sampling (NS) integral, where $u$ is the true GF, $d$ is the given data and $M$ is a model.
Namely
\begin{equation}
	p(u|d,M) = \int p(u|\theta) \underbrace{\frac{p(d|\theta) p(\theta)}{p(d)}d\theta}_\text{estimated by NS weights $w_i$} \approx \sum_i w_i p(u|\theta_i)
\end{equation}
We propose $\log p(u|d,M)$ as an interesting future quality statistic for probabilistic approaches as it expresses precisely what we would like to know from any inverse filtering method: how probable is the truth under your assumptions and given the data?

\paragraph{Importance of regularization}
We use Gaussian priors to regularize everything.
The importance of this, and just to see how expressive that can be, is illustrated by the fact that many inverse filtering methods differ mainly in priors: for example:
- double regularized total least squares in AM-GIF \citep{Bleyer2017}
- The QPR method applies a joint norm-
1 and norm-2 optimization \citep{Airaksinen2017}
- Gaussian prior on the filter coefficients of an AP filter \cite{Rao2018}

\paragraph{GCI detection}
BNGIF is unique in that it has adaptive GCI detection.
GCI detection is important for all GIF methods, because all GIF methods are pitch-synchronous in nature.

The sensitivity of GIF methods to the accuracy varies.
For example, \cite{Drugman2019} report that ``One of the most widely used GIF methods, the closed phase (CP) covariance analysis'', ``is sensitive to the extraction
of the closed phase position, and even small errors might result in severe
distortion of the estimated glottal excitation''

Several strategies exist to cope with this problem
several inverse filtering approaches are designed to deal with inaccuracies using weighting windows \cite{Drugman2019}
For example \citep{Chien2017} list two of these, which differ only in weight functions
and there is IAIF, which uses a multiple-pass technique and seems to be the only one not relying on this

BNGIF uses a different approach: while it can also optionally use prior estimates of the GCIs, it also REFINES them, as GCIs are important statistics of the speech signal in their own right, with applications in multi-speaker separation and prosody modification, for example \citep{Rao2006} (and indeed, accurate GCI detection is a problem in acoustic phonetics in its own right \citep{Drugman2012}).
So it has a strategy of not only being robust to GCI misspecification, but actually trying to uncover the GCIs themselves, as they are valuable information (statistics) of the speech signal in their own right.
It does this without needing to specify weighting windows and it Can handle errors in GCI and formant detection; Errors of Praat estimates are calibrated with known ground-truth databases and incorporated

\paragraph{Elimination of windowing procedures and other preprocessing}

Contrarily to the conventional extraction of spectral envelope based fea-
tures (such as the MFCC or LPC parameters) which is carried out asyn-
chronously,
the estimation and parameterisation of the glottal source (as it
will be explained in Section 4) generally requires to process windows whose
duration is proportional to the pitch period, as well as the knowledge of the
6GCI position. This section aims at providing a review of the existing tools
necessary for proper synchronization: pitch tracking in Section 3.1, speech
polarity detection (Section 3.2) and finally GCI determination in Section 3.3.

---

Angle: GIF methods are usually pitch-synchronous, so no real windowing is used often I think.
One pitch period equals one window frame.
But weighting.

Two windows: frame windows and weighting windows

Frame windows on $d(t)$: already annoying
Using this method, a common 10-50 ms speech frame, which depends on $F_0$ (longer frame if $F_0$ lower) \citep{Airaksinen2014}
``windowing is of crucial importance in order to achieve a correct deconvolution'' \citep{Drugman2011}

Weighting windows on the error $e(t)$ in weighted LP methods: even more annoying to get right.
Idea goes back to \citep{Pinson1963} and preceptual linear coding \citep{Schroeder1999}
These serve to lessen influence of GCI errors in pitch sync analyses, but still need to be parametrized (specified).
General idea: weighted linear prediction \citep{Ma1993}
For example
AME windowing in QPR and QPR has several parameters and is even more critical:
``The Quasi closed phase (QCP) method [7] uses the WLP to perform the inverse filtering using a special temporal window, called attenuate main excitation (AME), based the GCI locations. The GIF based on quadratic programming (QPR) [18] is motivated by QCP and uses both GCIs/GOIs to minimize the energy in the closed phase of the glottal flow. The lip radiation and the vocal tract filters are jointly estimated using quadratic programming. The methods QPR and QCP have been shown to be the state-of-the art methods for the GIFs. But one of the limitations of these methods is that they are sensitive to the GCI/GOI estimation errors and accurately detecting the closed phase is challenging.'' \citep{Rao2018}

Three different weighing functions are shown in Fig 1 in \citep{Gowda2020}. All of these have free parameters to choose.

\citep{Rao2018} infer the WLP window as part of their model

Related to the above: want a pitch-synchronous model
Elimination of windowing and averaging procedures. A typical method to measure formants is to slide over the signal with a tapering window, estimate the formant frequency, bandwidth
and peak amplitude in each window, and then to average these estimates over the windows \citep{Rabiner2007}.
In our approach, the pitch-synchronous nature of the model eliminates any windowing procedure
(and thus various user-made choices) by making use of the pitch period as a natural time scale \citep{Chen2019}.

No preemphasis

No ``specifically crafted weighting function'' : ``temporally weighted linear prediction (WLP [22]) with a specifically crafted weighting function (e.g., attenuated main excitation (AME) [23] or inverted GCI-centered Gaussian [24]) greatly increases the accuracy of formant esimation [23] and GIF [18].'' \citep{Airaksinen2017}

Inverse filtering methods use windowing to deal with the nonstationary nature of speech.
This is considered a mostly harmless approach, perhaps from familiarity with standard signal processing methods, and probably sufficient for many GIF purposes.
Nevertheless, windowing involves choices: the window length and the window function (Hanning, Hamming etc).
And these choices might have more impact than is typically considered.
For example, windows are typically 10-50 ms speech frame, which depends on $F_0$ (longer frame if $F_0$ lower) \citep{Airaksinen2014}
And \cite[p.~xxx]{Drugman2011} write that ``windowing is of crucial importance in order to achieve a correct deconvolution''.

\paragraph{Probabilistic formant tracking}

Formant tracking is usually seen as separate from the GIF problem, as within the LP framework simply adding additional pole pairs can compensate roughly and efficiently for the contribution of the source to the speech signal \citep{Atal1971,Rabiner1993,Schroeder1999}.
Nevertheless, as we argued above, we might expect higher accuracy using a holistic approach wherein formant tracks are derived directly from the inferred filters which need to be done in GIF anyway, especially for high $F_0$ to escape the phenomenon of harmonic attraction (see below).
Another point is that this amounts to pitch-synchronous formant tracking, for which theoretical arguments \citep{Chen2019} show supremacy over sliding based (asynchronous) approaches, which are the norm today.

We use latent GPs to model the formant trajectories which are calibrated on the VTRFormants database rather than polynomials with a specific order-to-be set as in \citep{Gowda2020}.
In addition, our latent formant trajectories allow for correlations, as in \citep{Mehta2012}.
In addition, our latent formant trajectories can be conditioned on (partially observed) estimates and can take into account probable errors on these estimates.

Most formant tracking algorithms attempt to correct
formant selection error (i.e., formant jumps; e.g., wrongly
selecting F3 as F2) and usually result in smoother sets of
formant values but cannot correct for bias toward the nearest
strong harmonic; one can end up with very smooth formant
tracks at very wrong frequencies. The default tracking func-
tion in Praat implements the Viterbi algorithm (Viterbi,
1967) to select the optimal (smoother) paths through for-
mant candidates, but it does not change the LPC-estimated
formant value itself (i.e., F0 bias remains). \citep{Whalen2022}

The need for manual correction of formant measurements

Errors of Praat estimates are calibrated with known ground-truth databases and incorporated

Ability to derive error bars on the formant frequencies, bandwidths and peak amplitudes.
Elimination of windowing and averaging procedures. A typical method to measure formants in a
SSV is to slide over the signal with a tapering window, estimate the formant frequency, bandwidth
and peak amplitude in each window, and then to average these estimates over the windows [9].
In our approach, the pitch-synchronous nature of the model eliminates any windowing procedure
(and thus various user-made choices) by making use of the pitch period as a natural time scale [12].
In addition, the formant frequencies and bandwidths are estimated simultaneously in each period,
which can be understood as a generalized averaging operation over pitch periods ([11] Section 7.5).
“Automatic” model order determination. This is done by inferring the most probable model order
given the SSV (and the model). This can be contrasted with traditional LPC analysis, where the
number of poles must be decided by the user on the basis of several well-established guidelines,
but where the final judgment ultimately remains qualitative.

Measuring the formants of a given speech fragment is a routine preoccupation in the field of acoustic
phonetics as formants can be said to carry basic information—above all to human listeners—about
uttered phonemes [5], speaker sex, identity and physique [6], medical conditions [7], etc.

Although estimating formants from speech is a well-established practice,

\begin{quote}
	The specification of speech by its formant patterns can be challenging, even
	with the development of powerful methods of digital signal processing. The
	uncertainties of formant analysis are widely acknowledged (Bickley, 1989;
	Hillenbrand, Getty, Clark and Wheeler, 1995; Ladefoged, 1967; Maurer, 2016).
	Almost inevitably, the search for formants is aided by knowledge of acoustic
	phonetics, even if this approach suffers from a fundamental circularity
	(Ladefoged, 1967). Formant estimation can be a process in which knowledge
	about likely formant locations leads to an efficient inspection of the
	acoustic data and can serve as a check on automatic analyses that may
	generate spurious formants or miss a formant altogether. \citep[][p.~75]{Kent2018}
\end{quote}

\paragraph{Probabilistic antiformant tracking}
BNGIF can model antiformants directly as the zero pairs of a pole-zero expansion of the rational transfer function $\htilde(x)$.
Because $\htilde(x)$ is formulated in the time domain (see Section~\ref{sec:irvt}) however, these zero pairs are implicit as the roots of the numerator of $\htilde(x)$, and need not correspond to antiformants directly.
Nevertheless, these zero pairs are still subject to similar inter-pitch period correlations as the pole pairs, such that probabilistic antiformant tracking is still possible with BNGIF.

We are not aware of other GIF methods with this ability, since GIF methods almost invariably assume all-pole transfer functions \citep{Alku2011,Kadiri2021,Bleyer2017}.
That being said, the KARMA \citep{Mehta2012} algorithm mentioned above is capable of probabilistic antiformant tracking, but it is not a GIF method.
Its authors write that ``antiformant tracking remains
a challenging task in speech analysis'' \citep[p.~11]{Mehta2012}, and the effectiveness of BNGIF for this task remains to be seen.

``As a final observation, antiformant tracking remains
a challenging task in speech analysis. Antiresonances
are typically less strong than their resonant counterparts
during nasalized phonation, and the estimation of sub-
glottal resonances continues to rely on empirical relation-
ships rather than direct acoustic observation (Arsikere
et al., 2011).'' \citep[p.~11]{Mehta2012}

\end{chaptersections}