% !TeX root = ../thesis.tex
\chapter{Conclusion\label{chapter:7}}

\citedepigraph{%
Today (1982), programming and running a computer is much easier than actually thinking about a problem. If the result is unsatisfactory, there is an understandable tendency to blame the algorithm and the method that produced it, rather than the faulty application.
}{Jaynes (1982)}{Jaynes1982}

For each contribution we have made a theoretical connection to acoustic phonetics.
This connection is prior knowledge in Bayesian terms.

Effective regularization = realistic priors

\begin{quote}
    But every Bayesian problem is open-ended; no matter how much
analysis you have completed, this only suggests still other kinds of prior information that you might
have had, and therefore still more interesting calculations that need to be done, to get still deeper
insight into the problem.
A person who tries to present a Bayesian solution, being obliged to produce a finite sized
manuscript in a finite time, must forego mentioning many other interesting things about the problem
that he became aware of while writing it.
[...] In effect, anyone writing about a Bayesian solution must draw a kind of artificial horizon about
the problem, beyond which he dare not tread however great the temptation. 
\end{quote} % https://bayes.wustl.edu/etj/node2.html: Straight line fitting - a Bayesian solution

The linear acoustic theory offers a somewhat simplified
view of the physics of speech production, but it is still a
very effective and widely used representation of voice signals for speech processing applications (e.g., speech coding,
synthesis, parameterization) and acoustic phonetics analyses \cite{Perrotin2021}

\section{Applications}

Next to GIF, the model can be used for more general tasks such as speech data augmentation and speech restoration.

Three main application 3 areas can be
distinguished: (i) fundamental study of voice communication, including both speech and singing,
(ii) medical applications \citep{Ng2008}, and (iii) speech technology applications
\citep{Alku2011}
(iv) forensic: \citep{Rose2002,Hughes2019,Bonastre2015,Becker2008,Nolan2001}

Measuring the formants of a given speech fragment is a routine preoccupation in the field of acoustic
phonetics as formants can be said to carry basic information—above all to human listeners—about
uttered phonemes [5], speaker sex, identity and physique [6], medical conditions [7], etc.
Accordingly, when formants are used as one of the pieces of information by a speech processing
computer program trying to determine, say, the height of a speaker [8], it is desirable to acknowledge
the uncertainty in the formant measurement, as this uncertainty propagates to the uncertainty about
the speaker’s height. While our contention that such uncertainty quantification is desirable stems
mainly from a principled point of view [9], we argue that in critical cases such as forensic speaker
identification [10], the ability to assign a degree of confidence to formant measurements—upon
which further conclusions rest—is valuable, perhaps essential, and well worth the considerable extra
computational effort required (As far as we know, while “there is a huge and increasing demand for
[forensic speaker identification] expertise in courts” [10] (p. 255), uncertainty quantification for formant
measurements is currently not in (widespread) use in forensics [10–12]. We are aware of several works
on quantifying and discussing the nature of the variability and reliability of formant measurements
that have been published quite recently [2,13–17]; this matter is discussed further in the conference
paper under the umbrella term “the formant measuring problem”). In more routine circumstances
one may simply take the error bars on the formant estimates as a practical measure of the computer
program’s trust in its own output. As with many things, the use for error bars or confidence intervals
for formant measurements depends strongly on the application and available resources at hand.


Although ``the result yielded by GIF is a temporal signal, the glottal volume velocity waveform which is an estimate of a real acoustical entity of the human voice production process'' \citep[p.~640]{Alku2011}, we take a more modest outlook.
On the one hand, we defintely look at it as a real problem because our priors reflect that and source-filter theory is succesful.
On the other hand, source-filter theory has its limitations \citep{Chen2016,Maurer2016} and many practical issues arise; for example, the speech signal is a recording and contains radiation effects and reverberation, all of which contaminate the signal and decrease SNR.
We take a pragmatic look and look at this as a typical deconvolution problem, i.e. an typical inverse problem with which science is filled up.
This means that we simply assume source-filter theory to be accurate to 5 kHz; we do not go into physiological details; etc.
All our error estimates are conditional on this assumption.
It will be most accurate in the case of voiced speech, which is considered an important speech sound class \citep{Alku2011}, but nonparametric nature will kick in in other cases such as nonvoiced, whispered and even plosives.


With the advent of modern machine learning techniques recently the problem has been recast within the general task of extracting excitation information from speech \citep{Kadiri2021}.
In this light source-filter separation may be said to be a costly though complete solution since any excitation statistic (such as $F_0$ and OQ) may be derived from the source signal.

A tailored VI algorithm for BNGIF also seems possible to derive.
Something similar has been done in \citep{Yoshii2013} 

\section{Future work}

\paragraph{Speedup}

Take advantage of linearity in the PZ model: nested models

Just do block tridiagonaly Cholesky
Factoring block tridiagonal symmetric positive definite matrices (Intel)
Or even: parallel implementation of the Cholesky factorization of a positive definite symmetric matrix when that matrix is block tridiagonal. \citep{Cao2002}

For detrending, we can do nested models (see vonderLinden book) and trans-dimensional nested sampling (Brewer2015).

Use elliptical slice sampling because many priors are Gaussian \citep{Murray2010}

\paragraph{More types of voicedness}
Bart: Ik denk dat je "model voiced speech" bedoelt, inderdaad de meest gebruikte vorm van voicing, maar het kan nuttig zijn te zeggen dat er meer soorten voicing zijn (creaky voice, breathy voice, falset, fluisteren) en wat precies het kenmerk van modal voice is (is  dat de meest regelmatige, minst ruizige manier?) 
Is er overigens echt geen literatuur die zich bezighoudt met de andere soorten voicing?

Several previous studies have indicated that the accuracy of
GIF methods is, in general, sufficient in estimating the glottal
flow from low-pitched male voices [3], [11]. However, when
the fundamental frequency $F_0$ of speech increases the performance of GIF methods generally deteriorates [2]. In addition to $F_0$, the type of phonation (i.e., modal, breathy, pressed) affects
the accuracy of GIF (depending on the method).
\citep{Airaksinen2014} p. 596


Work on babbling or toddlers’ speech is particularly
prone to error, given the high F0s of productions of young
children, but formants and even bandwidths are sometimes
reported (e.g., Robb et al., 1997). \citep[][p.~939]{Whalen2022}

"Analysis of high-pitched voices (e.g. for children), expres-
sive speech and conversational data are also among the challenges to tackle
over the next decades." \citep{Drugman2019}

\paragraph{More testing}

Achilles heel is that we could not test on large databases.
But we have contributed lines of thought.
And possible optimizations of code needed for applications on large databases are indicated for each algorithm [in github or perhaps in the thesis].

Databases to calibrate priors are very Western-centered.
APLAWD is UK British.
TIMIT is United States.
This could be improved.

\section{Conclusion}

The theme of the thesis is that much prior knowledge about the speech signal or low-dimensional derivatives of it (such as formants, fundamental frequency, etc.) is available, and a consistent way of utilizing this knowledge is in the form of Bayesian (probabilistic) inference. Another theme is the utilization of modern machine learning techniques (Gaussian processes, MCMC, automatic differentiation, variational inference, GPU) to solve the aforementioned inference problem.

Applications to speech processing where GPs model raw speech data are rare \citep{Koriyama2020}.

can generate surrogate speech data from posterior conditioned on speech data

For the prior, there are several reasons to prefer $\log x_k/x_{k-1}$ as the primary expression.

For the detrending, we show how the trend can be derived from source-filter theory.
We have highlighted the historical connection between formants and steady-state vowel.
It is logical that our first work starts here (i.e., steady-state vowels), because everything is well-defined and easy by virtue of the steady-state.
Though of course a priority should be to go well beyond steady-state; speech is not steady-state!

For high-precision formant measurement, we introduce probabilistic peak-picking.

For joint inverse filtering, the generalization of pulse models (Alku and Titze) and the idea of modeling a pulse (zero integral of first derivative).

Conclusion: we hoped to show that the Bayesian framework is a viable approach to problems in acoustic phonetics because there is a lot of prior knowledge which can be incorporated into the algorithms.

We also contributed two new priors: Pareto chain and the nonparametric dGF prior.

The problems have solved have the following compression factors in ban:
Steady-state vowels: about 13 bans, which is close to the Enigma problem of WWII. Or the number of trees on Earth.
Glottal flow priors: about XXX bans
Voiced speech: about XXX bans. How much is a sudoku? How much is the black hole picture?
This factors are small, given that a scheduling problem for a medium-sized school is around 1400 bans \citep{Bontekoe2006}.
Of course, we did everything we could to get these bans XXX as low as possible -- the whole point of the priors is make them as useful as possible.
Most of this entire thesis is literally an effort to keep these XXX bans as small as possible.

This work can also be used for mammals and other animals.
One might object that the priors of this work are tuned towards humans, but in practice tools like Praat, which are heavily tuned towards humans, are used anyway!
At least in our case we just use the priors to speed up computation and nudge the solution to having properties we know it must have -- but the data is still free to disagree, and we can know that if we allow sufficient computional budget.
So in that respect this is a step forward compared to just using Praat and similar programs.

