{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jax GIG implementation\n",
    "\n",
    "Yoshii+ (2013) uses same parametrization as [Wikipedia](https://en.wikipedia.org/wiki/Generalized_inverse_Gaussian_distribution).\n",
    "\n",
    "There is a reference implementation at Scipy: [`scipy.stats.geninvgauss.entropy`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.geninvgauss.html) which we test against.\n",
    "\n",
    "- Note: its differential `entropy()` actually uses quadrature; we use analytical formula from Wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bngif.gig import GIG\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import scipy.stats as sp\n",
    "from numpy.testing import assert_allclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 1)   Compare our closed-form moments to SciPy\n",
    "# ---------------------------------------------------------------------\n",
    "def test_against_scipy_geninvgauss():\n",
    "    rng = np.random.default_rng(0)\n",
    "\n",
    "    for _ in range(20):\n",
    "        p = float(rng.uniform(1.2, 5.0))  # mean exists for p>1\n",
    "        a = float(rng.uniform(0.1, 6.0))\n",
    "        b = float(rng.uniform(0.1, 6.0))\n",
    "        g = GIG(p=p, a=a, b=b)\n",
    "\n",
    "        mean_jax, inv_jax, log_jax = g.moments()\n",
    "\n",
    "        # SciPy reference via .to_scipy()\n",
    "        rv = g.to_scipy()\n",
    "        mean_ref = rv.mean()\n",
    "        inv_ref = rv.expect(lambda x: 1.0 / x)\n",
    "        log_ref = rv.expect(np.log)\n",
    "\n",
    "        assert_allclose(mean_jax, mean_ref, rtol=1e-11, atol=1e-13)\n",
    "        assert_allclose(inv_jax, inv_ref, rtol=1e-8, atol=1e-13)\n",
    "        assert_allclose(log_jax, log_ref, rtol=1e-7, atol=1e-11)\n",
    "\n",
    "\n",
    "test_against_scipy_geninvgauss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = np.array(1 / 4)\n",
    "rho = np.array(0.984)\n",
    "tau = np.array(1.6484)\n",
    "\n",
    "g = GIG(gamma, rho, tau)\n",
    "\n",
    "g.moments() # OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = g.to_scipy()\n",
    "\n",
    "a = np.array(1)\n",
    "b = np.array(1)\n",
    "\n",
    "gamma = sp.gamma(a, scale=1/b)\n",
    "\n",
    "# -Eq( log q )\n",
    "k1 = rv.entropy()\n",
    "\n",
    "# Eq( log p)\n",
    "k2 = rv.expect(lambda x: gamma.logpdf(x))\n",
    "\n",
    "d_kl = -k1 - k2\n",
    "\n",
    "d_kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 2)   Inverse-Gaussian special case   (p = −½,  b = 1/μ,  scale = μ)\n",
    "#       E[X] should equal μ\n",
    "# ---------------------------------------------------------------------\n",
    "def test_inverse_gaussian_mean():\n",
    "    mu = 2.0\n",
    "    p, b = -0.5, 1.0 / mu\n",
    "    g = GIG(p=p, a=b, b=b)  # Y ~ GIG scale=1\n",
    "    mean_y, *_ = g.moments()\n",
    "    mean_x = mu * float(mean_y)  # X = μ·Y\n",
    "\n",
    "    scipy_mean = sp.invgauss(mu).mean()\n",
    "    assert_allclose(mean_x, scipy_mean, rtol=1e-11, atol=1e-13)\n",
    "\n",
    "\n",
    "test_inverse_gaussian_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 3)   Gamma limit:  b → 0⁺  ⇒  GIG(p,a,b) →  Gamma(k=p, θ=2/a)\n",
    "# ---------------------------------------------------------------------\n",
    "from bngif.gig import Gamma\n",
    "\n",
    "\n",
    "def test_gamma_subclass():\n",
    "    rng = np.random.default_rng(321)\n",
    "\n",
    "    for _ in range(10):\n",
    "        k = rng.uniform(1.2, 6.0)  # shape (k>1 ⇒ finite entropy)\n",
    "        rate = rng.uniform(0.4, 5.0)  # λ\n",
    "        g = Gamma(shape=k, rate=rate, eps=1e-10)\n",
    "\n",
    "        mean, inv, log = g.moments()\n",
    "        H = g.entropy()\n",
    "\n",
    "        rv = g.to_scipy()\n",
    "        assert_allclose(mean, rv.mean(), rtol=1e-8)\n",
    "        assert_allclose(H, rv.entropy(), rtol=1e-8)\n",
    "\n",
    "        # gradients wrt shape & rate are finite\n",
    "        dH_dshape = jax.grad(lambda s: Gamma(s, rate).entropy())(k)\n",
    "        dH_drate = jax.grad(lambda r: Gamma(k, r).entropy())(rate)\n",
    "        assert np.isfinite(dH_dshape) and np.isfinite(dH_drate)\n",
    "\n",
    "\n",
    "test_gamma_subclass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 4)   Reciprocal property:  X~GIG(p,a,b)  ⇒  1/X ~ GIG(−p,b,a)\n",
    "# ---------------------------------------------------------------------\n",
    "def test_reciprocal_identity():\n",
    "    p, a, b = 1.8, 2.0, 0.7\n",
    "    mean_x, mean_invx, _ = GIG(p=p, a=a, b=b).moments()\n",
    "    mean_x_recip, *_ = GIG(p=-p, a=b, b=a).moments()\n",
    "\n",
    "    assert_allclose(mean_invx, mean_x_recip, rtol=1e-12, atol=1e-14)\n",
    "\n",
    "\n",
    "test_reciprocal_identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 5)   Entropy: closed-form vs SciPy numeric integration\n",
    "#      + jit- and grad- friendliness\n",
    "# ---------------------------------------------------------------------\n",
    "from bngif.gig import entropy as gig_entropy\n",
    "\n",
    "\n",
    "def test_entropy_and_autodiff():\n",
    "    rng = np.random.default_rng(42)\n",
    "\n",
    "    # use a handful of random parameter triples that keep SciPy quadrature cheap\n",
    "    for _ in range(5):\n",
    "        p = float(rng.uniform(0.4, 3.0))  # finite entropy, away from tails\n",
    "        a = float(rng.uniform(0.2, 4.0))\n",
    "        b = float(rng.uniform(0.2, 4.0))\n",
    "        g = GIG(p=p, a=a, b=b)\n",
    "\n",
    "        # --- reference via SciPy numeric integration -----------------\n",
    "        entropy_ref = g.to_scipy().entropy()\n",
    "\n",
    "        # --- our closed form ----------------------------------------\n",
    "        entropy_val = g.entropy()\n",
    "        assert_allclose(entropy_val, entropy_ref, rtol=1e-6, atol=1e-7)\n",
    "\n",
    "        # --- jit works ---------------------------------------------\n",
    "        entropy_jit = jax.jit(gig_entropy)\n",
    "        assert_allclose(entropy_jit(p, a, b), entropy_val, rtol=1e-9, atol=1e-9)\n",
    "\n",
    "        # --- gradients wrt a and b exist and are finite ------------\n",
    "        grad_a = jax.grad(lambda aa: gig_entropy(p, aa, b))(a)\n",
    "        grad_b = jax.grad(lambda bb: gig_entropy(p, a, bb))(b)\n",
    "\n",
    "        for gval in (grad_a, grad_b):\n",
    "            assert np.isfinite(gval), \"NaN/Inf gradient detected\"\n",
    "\n",
    "\n",
    "test_entropy_and_autodiff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the PDF on the three scales $x,1/x,\\log x$. Note $1/x \\sim GIG(-p,a,b)$ -- simple negation of order $p$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotting import iplot\n",
    "\n",
    "gig = GIG(p=1.0, a=1.0, b=1.0).to_scipy()\n",
    "\n",
    "x = np.linspace(gig.ppf(0.01), gig.ppf(0.99), 100)\n",
    "y = 1 / x\n",
    "z = np.log(x)\n",
    "\n",
    "\n",
    "def pdfx(x):\n",
    "    return gig.pdf(x)\n",
    "\n",
    "\n",
    "def pdfy(y):\n",
    "    return gig.pdf(1 / y) * (1 / y**2)  # Jacobian for change of variables\n",
    "\n",
    "\n",
    "def pdfz(z):\n",
    "    return gig.pdf(np.exp(z)) * np.exp(z)\n",
    "\n",
    "\n",
    "iplot(x, pdfx(x), title=\"GIG PDF\", xlabel=\"x\", ylabel=\"PDF\")\n",
    "iplot(y, pdfy(y), title=\"GIG PDF (reciprocal scale)\", xlabel=\"y = 1/x\", ylabel=\"PDF\")\n",
    "iplot(z, pdfz(z), title=\"GIG PDF (log scale)\", xlabel=\"z = log(x)\", ylabel=\"PDF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "I = 400\n",
    "alpha = 1.0\n",
    "\n",
    "iplot(\n",
    "    Gamma(alpha / I, alpha).to_scipy().rvs(I),\n",
    "    title=\"Gamma process prior\",\n",
    "    xlabel=\"index i\",\n",
    "    ylabel=\"theta_i\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_w = b_w = 1.0\n",
    "a_e = b_e = 1.0\n",
    "\n",
    "z = {\n",
    "    \"nu_w\": Gamma(a_w, b_w),\n",
    "    \"nu_e\": Gamma(a_e, b_e),\n",
    "    \"theta\": Gamma(jnp.ones(I) * alpha / I, alpha),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_gig = lambda x: isinstance(x, GIG)\n",
    "\n",
    "\n",
    "entropies = jax.jit(\n",
    "    lambda t: jax.tree_util.tree_map(\n",
    "        lambda d: d.entropy(),\n",
    "        t,\n",
    "        is_leaf=is_gig,\n",
    "    )  # <-- Don't unflatten GIG\n",
    ")\n",
    "\n",
    "entropies(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
