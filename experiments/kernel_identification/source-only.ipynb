{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpjax as gpx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from iklp.hyperparams import pi_kappa_hyperparameters, solve_for_alpha\n",
    "from iklp.mercer import psd_svd\n",
    "from iklp.run import CriterionState, print_progress, vi_run_criterion\n",
    "from iklp.state import (\n",
    "    LatentVars,\n",
    "    compute_expectations,\n",
    "    sample_x_from_z,\n",
    "    sample_z_from_prior,\n",
    ")\n",
    "from utils.jax import maybe32, vk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernels = [\n",
    "    gpx.kernels.Matern12(),\n",
    "    gpx.kernels.Matern32(),\n",
    "    gpx.kernels.Matern52(),\n",
    "    gpx.kernels.RBF(),\n",
    "]\n",
    "\n",
    "I = len(kernels)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(7, 6), tight_layout=True)\n",
    "\n",
    "x = jnp.linspace(-3.0, 3.0, num=200).reshape(-1, 1)\n",
    "\n",
    "meanf = gpx.mean_functions.Zero()\n",
    "\n",
    "for k, ax in zip(kernels, axes.ravel(), strict=False):\n",
    "    prior = gpx.gps.Prior(mean_function=meanf, kernel=k)\n",
    "    rv = prior(x)\n",
    "    y = rv.sample(key=vk(), sample_shape=(10,))\n",
    "    ax.plot(x, y.T, alpha=0.7)\n",
    "    ax.set_title(k.name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K = jnp.stack([k.gram(x).to_dense() for k in kernels], axis=0)\n",
    "\n",
    "\n",
    "Phi = psd_svd(K)\n",
    "\n",
    "print(\"Phi shape\", Phi.shape)\n",
    "print(\n",
    "    \"SVD decomposition allclose()?\", jnp.allclose(K, Phi @ Phi.swapaxes(1, 2))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = solve_for_alpha(I)\n",
    "\n",
    "pi = 0.95\n",
    "kappa = 1.0\n",
    "\n",
    "\n",
    "h = pi_kappa_hyperparameters(Phi, alpha=maybe32(alpha), pi=pi, kappa=kappa, P=0)\n",
    "\n",
    "z = sample_z_from_prior(vk(), h)\n",
    "\n",
    "print(\"nu_w\", z.nu_w)\n",
    "print(\"nu_e\", z.nu_e)\n",
    "print(\"sum = \", z.nu_w + z.nu_e)\n",
    "print(\"pitchedness = \", z.nu_w / (z.nu_w + z.nu_e))\n",
    "\n",
    "x = sample_x_from_z(vk(), z, h)\n",
    "plt.plot(x)\n",
    "plt.xlabel(\"x\")\n",
    "plt.title(\"Sampled x\")\n",
    "plt.show()\n",
    "\n",
    "power = jnp.mean(x**2)\n",
    "print(\"power(x)/(nu_w + nu_e) = \", power / (z.nu_w + z.nu_e))\n",
    "\n",
    "\n",
    "def compute_power_distibution(z):\n",
    "    \"\"\"Return normalized power distribution for (noise, kernel_1, ..., kernel_I)\"\"\"\n",
    "    power = jnp.concatenate((jnp.array([z.nu_e]), z.nu_w * z.theta))\n",
    "    return power / jnp.sum(power)  # (I+1,)\n",
    "\n",
    "\n",
    "def compute_state_power_distribution(state):\n",
    "    E = compute_expectations(state)\n",
    "    z = LatentVars(E.theta, E.nu_w, E.nu_e, None)\n",
    "    return compute_power_distibution(z)\n",
    "\n",
    "\n",
    "true_power_distribution = compute_power_distibution(z)\n",
    "\n",
    "plt.stem(\n",
    "    true_power_distribution,\n",
    "    linefmt=\"r-\",\n",
    "    markerfmt=\"ro\",\n",
    "    label=\"true power distribution\",\n",
    "    basefmt=\" \",\n",
    ")\n",
    "plt.legend()\n",
    "plt.xlabel(\"kernel index $i$\")\n",
    "plt.ylabel(\"relative power\")\n",
    "plt.title(\"True power distribution across kernels and noise\")\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CMAP = plt.get_cmap(\"coolwarm\")\n",
    "\n",
    "\n",
    "def onstate(cs: CriterionState):\n",
    "    print_progress(cs)\n",
    "\n",
    "    i = cs.i\n",
    "    state = cs.state\n",
    "\n",
    "    E = compute_expectations(state)\n",
    "    z = LatentVars(E.theta, E.nu_w, E.nu_e, None)\n",
    "\n",
    "    print(f\"argmax_i(theta) = {np.argmax(E.theta)}\")\n",
    "\n",
    "    cmap = CMAP\n",
    "\n",
    "    color = cmap(i / 100)\n",
    "    if i % 1 == 0:\n",
    "        power_distribution = compute_state_power_distribution(state)\n",
    "        plt.plot(power_distribution, linewidth=1.0, color=color)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def vi_run_criterion_callback(*args, **kwargs):\n",
    "    assert \"callback\" not in kwargs\n",
    "    return vi_run_criterion(*args, **kwargs, callback=onstate)\n",
    "\n",
    "\n",
    "vi_run_criterion_callback = jax.jit(vi_run_criterion_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use global plot\n",
    "plt.figure()\n",
    "\n",
    "cs = vi_run_criterion_callback(vk(), x, h)\n",
    "\n",
    "true_power_distribution = compute_power_distibution(z)\n",
    "\n",
    "plt.stem(\n",
    "    true_power_distribution,\n",
    "    linefmt=\"r-\",\n",
    "    markerfmt=\"ro\",\n",
    "    label=\"true power distribution\",\n",
    "    basefmt=\" \",\n",
    ")\n",
    "\n",
    "I = len(kernels)\n",
    "labels = [\"noise\"] + [str(i) for i in range(I)]\n",
    "\n",
    "plt.xticks(ticks=np.arange(I + 1), labels=labels)\n",
    "plt.xlabel(\"kernel index $i$\")\n",
    "plt.ylabel(\"relative power\")\n",
    "plt.title(\"True power distribution across kernels and noise\")\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iklp.mercer_op import *\n",
    "from iklp.state import compute_auxiliaries\n",
    "\n",
    "aux = compute_auxiliaries(state)\n",
    "\n",
    "op = aux.Omega\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, noise = sample_parts(op, vk())\n",
    "\n",
    "plt.plot(x, label=\"x\")\n",
    "plt.plot(signal, label=\"signal\")\n",
    "plt.plot(noise, label=\"noise\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, noise = sample_parts_given_observation(op, x, vk())\n",
    "\n",
    "plt.plot(x, label=\"x\")\n",
    "plt.plot(signal, label=\"signal\")\n",
    "plt.plot(noise, label=\"noise\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
